{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d8e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Import and understand the dataset\n",
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "df.replace({r'\\r\\n':' '}, regex=True, inplace=True)\n",
    "\n",
    "# Implementing the BOW algorithm\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "all_stop_words = set(stopwords.words('english'))\n",
    "all_stop_words.remove('not')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text = df['text'][i].lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    text = [ps.stem(word) for word in text if word not in all_stop_words]\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)\n",
    "\n",
    "# Creating BOW model\n",
    "cv = CountVectorizer(max_features=42500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df['label_num']\n",
    "\n",
    "# Splitting the dataset into the training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3bf3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.966183574879227\n",
      "Model precision score: 0.9466666666666667\n",
      "Model recall score: 0.9372937293729373\n",
      "Model f1 score: 0.9419568822553899\n",
      "Average overall score performance: 0.9480252132935552\n",
      "[[716  16]\n",
      " [ 19 284]]\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "nb_multinomial = MultinomialNB()\n",
    "nb_multinomial.fit(X_train, y_train)\n",
    "y_pred_nb = nb_multinomial.predict(X_test)\n",
    "\n",
    "# Model Performance\n",
    "def model_score(y_true, y_pred):\n",
    "    acc_scor = accuracy_score(y_true, y_pred)\n",
    "    prec_scor = precision_score(y_true, y_pred)\n",
    "    recall_scor = recall_score(y_true, y_pred)\n",
    "    f1_scor = f1_score(y_true, y_pred)\n",
    "    overall_avg_score = (acc_scor + prec_scor + recall_scor + f1_scor) / 4\n",
    "\n",
    "    print(f'Model accuracy score: {acc_scor}')\n",
    "    print(f'Model precision score: {prec_scor}')\n",
    "    print(f'Model recall score: {recall_scor}')\n",
    "    print(f'Model f1 score: {f1_scor}')\n",
    "    print(f'Average overall score performance: {overall_avg_score}')\n",
    "\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Model Performance\n",
    "model_score(y_test, y_pred_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e7b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text to classify: ho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time ! i know that this time of year is extremely hectic , and that it ' s tough to think about anything past the holidays , but life does go on past the week of december 25 through january 1 , and that ' s what i ' d like you to think about for a minute .\n",
      "\n",
      "Naive Bayes Classifier Prediction: Ham\n"
     ]
    }
   ],
   "source": [
    "# Function to classify text using Naive Bayes\n",
    "def classify_text(input_text):\n",
    "    ps = PorterStemmer()\n",
    "    input_text = input_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    input_text = [ps.stem(word) for word in input_text if word not in all_stop_words]\n",
    "    input_text = ' '.join(input_text)\n",
    "\n",
    "    input_vector = cv.transform([input_text]).toarray()\n",
    "\n",
    "    nb_prediction = nb_multinomial.predict(input_vector)\n",
    "\n",
    "    return nb_prediction[0]\n",
    "\n",
    "# User input\n",
    "user_input = input(\"Enter a text to classify: \")\n",
    "\n",
    "# Classify using Naive Bayes\n",
    "nb_result = classify_text(user_input)\n",
    "\n",
    "# Print result\n",
    "print(f'\\nNaive Bayes Classifier Prediction: {\"Spam\" if nb_result == 1 else \"Ham\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5285c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text to classify: abasements darer prudently fortuitous undergone lighthearted charm orinoco taster railroad affluent pornographic cuvier irvin parkhouse blameworthy chlorophyll robed diagrammatic fogarty clears bayda inconveniencing managing represented smartness hashish academies shareholders unload badness danielson pure caffein spaniard chargeable levin\n",
      "\n",
      "Naive Bayes Classifier Prediction: Spam\n"
     ]
    }
   ],
   "source": [
    "# Function to classify text using Naive Bayes\n",
    "def classify_text(input_text):\n",
    "    ps = PorterStemmer()\n",
    "    input_text = input_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    input_text = [ps.stem(word) for word in input_text if word not in all_stop_words]\n",
    "    input_text = ' '.join(input_text)\n",
    "\n",
    "    input_vector = cv.transform([input_text]).toarray()\n",
    "\n",
    "    nb_prediction = nb_multinomial.predict(input_vector)\n",
    "\n",
    "    return nb_prediction[0]\n",
    "\n",
    "# User input\n",
    "user_input = input(\"Enter a text to classify: \")\n",
    "\n",
    "# Classify using Naive Bayes\n",
    "nb_result = classify_text(user_input)\n",
    "\n",
    "# Print result\n",
    "print(f'\\nNaive Bayes Classifier Prediction: {\"Spam\" if nb_result == 1 else \"Ham\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7caf07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
